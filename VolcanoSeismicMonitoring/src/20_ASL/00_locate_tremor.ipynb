{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d49506-4238-4d0f-a7e6-82633aa844ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygmt\n",
    "pygmt.show_versions()\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "grid = pygmt.datasets.load_earth_relief(\n",
    "    resolution=\"15s\", region=[144.5, 145.5, 13, 14.5], registration=\"gridline\"\n",
    ")\n",
    "fig.coast(region=\"g\", frame=True, shorelines=1)\n",
    "fig.show()\n",
    "\n",
    "example_grid = pygmt.load_dataarray('/Users/thompsong/.gmt/cache/srtm_tiles.nc')\n",
    "\n",
    "print(example_grid)\n",
    "\n",
    "import pygmt\n",
    "region = [-119.25, -118.95, 37.525, 37.725]\n",
    "pygmt.config(GMT_DATA_SERVER=\"https://oceania.generic-mapping-tools.org\")\n",
    "grid = pygmt.datasets.load_earth_relief(resolution=\"01s\", region=region)\n",
    "\n",
    "grid = pygmt.datasets.load_earth_relief(\n",
    "    resolution=\"30s\", region=[144.5, 145.5, 13, 14.5], registration=\"gridline\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f092ef7",
   "metadata": {},
   "source": [
    "# to do\n",
    "I do not think the misfit algorithm is working well. For real pyroclastic flow, it puts solutions too close to the station with highest displacement.  So rather than minimizing the normalized standard deviation, perhaps I minimize the absolute differences squared between real displacements and estimated displacements. Or the ratios of real to estimated? Perhaps I program in 3 misfit functions and see which is best. I possibly also need to do the iteration to smaller grid size to really refine locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f51f37c",
   "metadata": {},
   "source": [
    "# Amplitude Source Location (ASL)\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "### 1.1 Review\n",
    "\n",
    "In the previous tutorial, we estimated Reduced Displacement by assuming a source location, e.g. the summit of a volcano. But it would be better if we locate volcano-seismic signals, and then compute Reduced Displacement. Most volcano-seismic signals cannot be located using traditional differential travel-time techniques, because they lack identifiable phases (sources are quasi-continuous, so phases are arriving all the time). So what else can we do?\n",
    "\n",
    "### 1.2 Motivation\n",
    "In summer 1996, I was fortunate enough as a graduate student to be asked to assist the British Geological Survey in its monitoring of the Soufriere Hills Volcano, Montserrat. As part of \"Team Seismic\" at the Montserrat Volcano Observatory, our job was to provide 24-7 monitoring of the lava dome eruption, which had been continuous since October 1995. Crucially, this involved two-way radio communications with others working on the slopes of the volcano, and warning them of seismicity, especially pyroclastic flows [Add video here from Lauren's Journeys program]. \n",
    "\n",
    "I had the idea that we could use the RSAM data to locate seismicity continuously, on a map on a monitor in the Ops Room. I created a proof-of-concept, using the 60-s RSAM data (the 2.56-s RSAM data wasn't captured), and applying calibration constants. We'll replicate that here, but use DSAM data, which has already been instrument-corrected. For simplicity - and speed which was important for a real-time system - we ignore the vertical dimension (topography and station elevations ignored), and assume an isotropic, homogeneous half-space.\n",
    "\n",
    "First, we will run a simulation, to demonstrate that our location technique works. Then we will compute locations for real DSAM data, and then for a known pyroclastic flow signal.\n",
    "\n",
    "### 1.3 Setup\n",
    "\n",
    "We need to import the following, to set things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f56f3de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import obspy\n",
    "localLibPath = Path.cwd().resolve().parents[0].joinpath('lib')\n",
    "sys.path.append(str(localLibPath))\n",
    "from SAM import DSAM\n",
    "#SDS_DIR = Path.cwd().parents[1].joinpath('data','continuous','SDS')\n",
    "#SAM_DIR = Path.cwd().parents[1].joinpath('data','continuous','SAM')\n",
    "RESPONSE_DIR = Path.cwd().parents[1].joinpath('data','responses')\n",
    "\n",
    "def montserrat_topo_map_alt(show=False, zoom_level=0, inv=None, add_labels=False, centerlon=-62.177, centerlat=16.711, contour_interval=100, topo_color=True):\n",
    "    #define etopo data file\n",
    "    # topo_data = 'path_to_local_data_file'\n",
    "    #topo_data = '@earth_relief_30s' #30 arc second global relief (SRTM15+V2.1 @ 1.0 km)\n",
    "    #topo_data = '@earth_relief_15s' #15 arc second global relief (SRTM15+V2.1)\n",
    "    #topo_data = '@earth_relief_03s' #3 arc second global relief (SRTM3S)\n",
    "    resolution = \"03s\"\n",
    "    pklfile = f'{centerlon}.{centerlat}.{zoom_level}.{resolution}.pkl'\n",
    "    \n",
    "    # define plot geographical range\n",
    "    diffdeglat = 0.08/(2**zoom_level)\n",
    "    diffdeglon = diffdeglat/np.cos(np.deg2rad(centerlat))\n",
    "    minlon, maxlon = centerlon-diffdeglon, centerlon+diffdeglon  #-62.25, -62.13\n",
    "    minlat, maxlat = centerlat-diffdeglat, centerlat+diffdeglat  # 16.66, 16.83\n",
    "    print(minlon, maxlon, minlat, maxlat)\n",
    "\n",
    "\n",
    "    if os.path.exists(pklfile):\n",
    "        with open(pklfile, 'rb') as fileptr:\n",
    "            print(f'Loading {pklfile}')\n",
    "            topo_data = pickle.load(fileptr)    \n",
    "    else:        \n",
    "        try:\n",
    "            print('Reading topo (earth relief) data from GMT website')\n",
    "            ergrid = pygmt.datasets.load_earth_relief(resolution=resolution, region=[minlon, maxlon, minlat, maxlat], registration=None)\n",
    "            print(\"topo_data downloaded\")\n",
    "            with open(pklfile, 'wb') as fileptr: \n",
    "                print(f'Writing {pklfile}')\n",
    "                # A new file will be created \n",
    "                pickle.dump(ergrid, fileptr)\n",
    "        except:\n",
    "            print(\"Cannot load any topo data\")\n",
    "            return\n",
    "\n",
    "    #print(ergrid)\n",
    "    \n",
    "    # Visualization\n",
    "    fig = pygmt.Figure()\n",
    "    \n",
    "    if topo_color:\n",
    "        # make color pallets\n",
    "        print('Making color pallet')\n",
    "        pygmt.makecpt(\n",
    "            cmap='topo',\n",
    "            series='-1300/1300/%d' % contour_interval,\n",
    "            continuous=True\n",
    "        )\n",
    "        print('Calling grdimage')\n",
    "        # plot high res topography\n",
    "        fig.grdimage(\n",
    "            grid=ergrid,\n",
    "            region=[minlon, maxlon, minlat, maxlat],\n",
    "            projection='M4i',\n",
    "            shading=True,\n",
    "            frame=True\n",
    "            )\n",
    "    \n",
    "    # plot continents, shorelines, rivers, and borders\n",
    "    fig.coast(\n",
    "        region=[minlon, maxlon, minlat, maxlat],\n",
    "        projection='M4i',\n",
    "        shorelines=True,\n",
    "        frame=True\n",
    "        )\n",
    "    \n",
    "    # plot the topographic contour lines\n",
    "    fig.grdcontour(\n",
    "        grid=ergrid,\n",
    "        interval=contour_interval,\n",
    "        annotation=\"%d+f6p\" % contour_interval,\n",
    "        limit=\"-1300/1300\", #to only display it below \n",
    "        pen=\"a0.15p\"\n",
    "        )\n",
    "    \n",
    "    if topo_color:\n",
    "        fig.colorbar(\n",
    "            frame='+l\"Topography\"',\n",
    "        #     position=\"x11.5c/6.6c+w6c+jTC+v\" #for vertical colorbar\n",
    "            )\n",
    "\n",
    "    \n",
    "    if inv:\n",
    "        seed_ids = inventory2seedids(inv, force_location_code='')\n",
    "        #print(seed_ids)\n",
    "        stalat = [inv.get_coordinates(seed_id)['latitude'] for seed_id in seed_ids]\n",
    "        stalon = [inv.get_coordinates(seed_id)['longitude'] for seed_id in seed_ids]\n",
    "        fig.plot(x=stalon, y=stalat, style=\"s0.4c\", fill=\"dodgerblue4\", pen='2p,blue')  \n",
    "        \n",
    "        if add_labels:\n",
    "            #print('Adding station labels')\n",
    "            for thislat, thislon, this_id in zip(stalat, stalon, seed_ids):\n",
    "                net, sta, loc, chan = this_id.split('.')\n",
    "                #print(thislat, thislon, net, sta, loc, chan)\n",
    "                fig.text(x=thislon, y=thislat, text=sta, textfiles=None, \\\n",
    "                        font=\"blue\",\n",
    "                        justify=\"ML\",\n",
    "                        offset=\"0.2c/0c\",)\n",
    "    \n",
    "    if show:\n",
    "        fig.show();\n",
    "\n",
    "\n",
    "    return fig\n",
    "\n",
    "from ASL import montserrat_topo_map, Grid, ASL, simulate_DSAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9490b-b35a-4239-893a-634a87b73584",
   "metadata": {},
   "source": [
    "## 2. Synthetic testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8d6b6",
   "metadata": {},
   "source": [
    "### 2.1 Map of Montserrat stations\n",
    "We generate a map of seismic stations with a vertical-component sensor, operational (though not necessarily working properly) on July 12, 2003. This 13-station network provides good azimuthal coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d040a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-62.260527595207385 -62.093472404792614 16.631 16.790999999999997\n",
      "Reading topo (earth relief) data from GMT website\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grdcut [ERROR]: Remote download is currently deactivated\n",
      "grdcut [ERROR]: Unable to obtain remote file @earth_relief_03s_g\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot load any topo data\n"
     ]
    }
   ],
   "source": [
    "invMVO = obspy.read_inventory(os.path.join(RESPONSE_DIR,'MV.xml'), format='stationxml')\n",
    "startt = obspy.UTCDateTime(2003,7,12,23,0,0)\n",
    "endt = obspy.UTCDateTime(2003,7,13,4,0,0)\n",
    "invMVO = invMVO.select(starttime=startt, endtime=endt)\n",
    "invMVO = invMVO.select(channel='*Z')\n",
    "#import pygmt\n",
    "#pygmt.config(GMT_DATA_SERVER=\"https://oceania.generic-mapping-tools.org\")\n",
    "montserrat_topo_map(inv=invMVO, show=True, add_labels=True, resolution='03s');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98232831",
   "metadata": {},
   "source": [
    "### 2.2 Define a grid of source locations and reduced displacement at those nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1cd754-4eeb-423d-a886-8431621c33fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_interval = 60\n",
    "synthetic_source = {}\n",
    "N = 10\n",
    "synthetic_source['lat'] = 16.69 + np.tile(np.arange(N)/200, N)\n",
    "synthetic_source['lon'] = -62.20 + np.repeat(np.arange(N)/200, N)\n",
    "synthetic_source['DR'] = np.ones(N*N) * 100.0 # 100 cm^2 everywhere\n",
    "synthetic_source['t'] = [obspy.UTCDateTime(0) + t * sampling_interval for t in range(N*N)]\n",
    "#print(synthetic_source)\n",
    "\n",
    "surfaceWaveSpeed_kms = 1.5\n",
    "peakf=8.0\n",
    "Q=23\n",
    "synthDSAMobj = simulate_DSAM(invMVO, synthetic_source, surfaceWaves=True, wavespeed_kms=surfaceWaveSpeed_kms, \\\n",
    "                             peakf=peakf, Q=Q, noise_level_percent=0.0)\n",
    "synthDSAMobj.plot(metrics='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8318f74b",
   "metadata": {},
   "source": [
    "### 2.3 Create grid with 100-m node spacing, 8 x 10 km "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff75415",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_spacing_m = 100\n",
    "grid_size_lat_m = 10000\n",
    "grid_size_lon_m = 8000\n",
    "nlat = int(grid_size_lat_m/node_spacing_m) + 1\n",
    "nlon = int(grid_size_lon_m/node_spacing_m) + 1\n",
    "gridobj = Grid(np.mean(synthetic_source['lat']), np.mean(synthetic_source['lon']), nlat, nlon, node_spacing_m)  \n",
    "gridobj.plot(node_spacing_m = node_spacing_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3f927",
   "metadata": {},
   "source": [
    "### 2.4 Plot synthetic source locations, and DR time series (all equal=100 ${cm}^2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f397ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aslobj = ASL(synthDSAMobj, 'mean', invMVO, gridobj)\n",
    "\n",
    "aslobj.plot(synthetic_source, zoom_level=1, threshold_DR=1.0, scale=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5771d671",
   "metadata": {},
   "source": [
    "### 2.5 Run location algorithm on synthetic source and plot resulting locations and DR time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd5e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aslobj.compute_grid_distances()\n",
    "\n",
    "aslobj.compute_amplitude_corrections(surfaceWaves=True, wavespeed_kms=surfaceWaveSpeed_kms, Q=Q, fix_peakf=peakf)\n",
    "\n",
    "time1 = time.time()\n",
    "source = aslobj.locate()\n",
    "time2 = time.time()\n",
    "print(f'Location algorithm took {time2-time1} s')\n",
    "aslobj.plot(source, zoom_level=1, scale=0.1, threshold_DR=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff38ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "fast_source = aslobj.fast_locate()\n",
    "time2 = time.time()\n",
    "print(f'Vectorized location algorithm took {time2-time1} s')\n",
    "aslobj.plot(fast_source, zoom_level=1, scale=0.1, threshold_DR=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259c97d",
   "metadata": {},
   "source": [
    "## 3 Locating real DSAM data: July 12, 2003 collapse\n",
    "\n",
    "Now we are confident in our ability to locate synthetic data correctly, and determine reduced displacement correctly, we will try to locate some real data. In this example, we use the 'VT' metric from the DSAM dataset. Recall that this is the mean amplitude of the signal (over 60-s time windows) after filtering between 4 and 18 Hz, rather than the 'mean' metric (or 'median', or 'rms' etc.) which are computed on signals filtered between 0.5 and 18 Hz. We do this because Jolly et al. (2002) determined that a 7-9 Hz bandpass was best for locating pyroclastic flows, and so the VT band is the one we have available that best matches this.\n",
    "\n",
    "### 3.1 Read inventory and DSAM data. Plot DSAM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "invMVO = read_inventory(os.path.join(paths['RESPONSE_DIR'],'MV.xml'), format='stationxml')\n",
    "startt = obspy.UTCDateTime(2003,7,12,23,0,0)\n",
    "endt = obspy.UTCDateTime(2003,7,13,4,0,0)\n",
    "dsamObj = DSAM.read(startt, endt, SAM_DIR=paths['SAM_DIR'], sampling_interval=60, ext='pickle', \\\n",
    "                     trace_ids=['MV.MBGH..BHZ', 'MV.MBLG..SHZ', 'MV.MBRY..BHZ', 'MV.MBSS..SHZ', 'MV.MBWH..SHZ'])  \n",
    "\n",
    "dsamObj.plot(metrics='VT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331d90c",
   "metadata": {},
   "source": [
    "### 3.2 Create dense grid (20-m node spacing) and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c61303",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = {'lat':16.71111, 'lon':-62.17722}\n",
    "node_spacing_m = 20\n",
    "grid_size_lat_m = 10000\n",
    "grid_size_lon_m = 8000\n",
    "nlat = int(grid_size_lat_m/node_spacing_m) + 1\n",
    "nlon = int(grid_size_lon_m/node_spacing_m) + 1\n",
    "gridobj = Grid(source['lat'], source['lon'], nlat, nlon, node_spacing_m)  \n",
    "gridobj.plot(node_spacing_m = node_spacing_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb37b4",
   "metadata": {},
   "source": [
    "### 3.3 Create ASL object, compute combined eometrical spreading and inelatic attenuation corrections for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442dc7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 23\n",
    "surfaceWaveSpeed_kms = 1.5 # km/s\n",
    "peakf = 8.0\n",
    "\n",
    "aslobj = ASL(dsamObj, 'rms', invMVO, gridobj)\n",
    "\n",
    "aslobj.compute_grid_distances()\n",
    "\n",
    "aslobj.compute_amplitude_corrections(surfaceWaves=True, wavespeed_kms=surfaceWaveSpeed_kms, Q=Q, fix_peakf = peakf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31d0d2",
   "metadata": {},
   "source": [
    "### 3.4 Run the amplitude location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = aslobj.fast_locate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e079965e",
   "metadata": {},
   "source": [
    "### 3.5 Plot sources and source reduced displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3b24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aslobj.plot(source, zoom_level=2, threshold_DR=100.0, scale=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160da14c",
   "metadata": {},
   "source": [
    "## 4. Locate a pyroclastic flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3552b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import obspy\n",
    "from obspy import read_inventory\n",
    "sys.path.append('../lib')\n",
    "import setup_paths\n",
    "paths = setup_paths.paths\n",
    "from SAM import DSAM\n",
    "from ASL import montserrat_topo_map, Grid, ASL, simulate_DSAM\n",
    "import pipelines\n",
    "\n",
    "# same parameters as before\n",
    "Q = 23\n",
    "surfaceWaveSpeed_kms = 1.5 # km/s\n",
    "peakf = 8.0\n",
    "\n",
    "# same grid as before\n",
    "source = {'lat':16.71111, 'lon':-62.17722}\n",
    "#node_spacing_m = 20\n",
    "node_spacing_m = 100\n",
    "grid_size_lat_m = 10000\n",
    "grid_size_lon_m = 8000\n",
    "nlat = int(grid_size_lat_m/node_spacing_m) + 1\n",
    "nlon = int(grid_size_lon_m/node_spacing_m) + 1\n",
    "gridobj = Grid(source['lat'], source['lon'], nlat, nlon, node_spacing_m)  \n",
    "\n",
    "# Load the waveform data & fix Montserrat Trace IDs\n",
    "st1 = obspy.read('/shares/hal9000/share/data/SEISAN_DB/WAV/DSNC_/1999/08/1999-08-12-1120-46S.MVO___019', format='seisan')\n",
    "st2 = obspy.read('/shares/hal9000/share/data/SEISAN_DB/WAV/DSNC_/1999/08/1999-08-12-1140-46S.MVO___019', format='seisan')\n",
    "st = st1 + st2\n",
    "pipelines.fix_montserrat_seed_ids(st)\n",
    "st.merge(method=0, fill_value=0)\n",
    "st = st.select(component='Z')\n",
    "#st.plot(equal_scale=False);\n",
    "\n",
    "# Load inventory\n",
    "invMVO = read_inventory(os.path.join(paths['RESPONSE_DIR'],'MV.xml'), format='stationxml')\n",
    "\n",
    "# drop bad traces. MBGH has no signal, MBMH is noisy. \n",
    "for tr in st.select(station=\"MBGH\"):\n",
    "    st.remove(tr) \n",
    "for tr in st.select(station=\"MBMH\"):\n",
    "    st.remove(tr)     \n",
    "\n",
    "# remove instrument response - and set units accordingly IMPORTANT!\n",
    "pre_filt = [0.4, 0.5, 18, 20]\n",
    "#pre_filt = [6.0, 7.0, 9.0, 10.0]\n",
    "st.remove_response(inventory=invMVO, pre_filt=pre_filt, output=\"DISP\", plot=False) \n",
    "for tr in st:\n",
    "    tr.stats['units'] = 'm'\n",
    "#st.plot(equal_scale=True);\n",
    "\n",
    "# compute DSAM data with 10-s time window\n",
    "for tr in st:\n",
    "    tr.stats['units'] = 'm'\n",
    "dsamObj = DSAM(stream=st, sampling_interval=10)\n",
    "#print(dsamObj)\n",
    "#dsamObj.plot(metrics='rms', equal_scale=True)\n",
    "\n",
    "source1 = {'lat':16.71111, 'lon':-62.17722}\n",
    "DRSobj = dsamObj.compute_reduced_displacement(invMVO, source1, surfaceWaves=True, Q=None, wavespeed_kms=1.5)\n",
    "\n",
    "DRSmaxrms = DRSobj.max(metric='VT')\n",
    "print(f'Maximum DRS assuming fixed source is: {DRSmaxrms}')\n",
    "#DRSobj.plot(equal_scale=True)\n",
    "\n",
    "aslobj = ASL(dsamObj, 'VT', invMVO, gridobj)\n",
    "\n",
    "aslobj.compute_grid_distances()\n",
    "\n",
    "aslobj.compute_amplitude_corrections(surfaceWaves=True, wavespeed_kms=surfaceWaveSpeed_kms, Q=None, fix_peakf = peakf)\n",
    "\n",
    "source_pf = aslobj.fast_locate()\n",
    "\n",
    "aslobj.plot(source_pf, zoom_level=1, threshold_DR=0.03, scale=0.2, join=True, number=10, equal_size=True, add_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66710f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aslobj.plot(source_pf, zoom_level=3, threshold_DR=0.03, scale=0.5, join=True, number=30, add_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e074175",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "\n",
    "I call the approach above \"naive\" ASL, because for simplicity (and speed, for real-time application) it ignores the vertical dimension, and assumes a homogeneous, isotropic half space (1-layer). It also considers the seismic source to be a point source, and assumes only one event is occurring at a time. In reality, pyroclastic flows cause multiple seismic sources per unit time, over an extended area, and this evolves with time as the flow moves downhill. Moreover, there can be numerous pyroclastic flows travelling down different flanks of the volcano at the same time, such as in a major dome collapse which may be comprised of dozens of pyroclastic flows that reach the coast. The average location determined by ASL is likely the top of the dome. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
